{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os;\n",
    "import sys;\n",
    "import numpy as np;\n",
    "from sklearn.linear_model import LinearRegression;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eng_read_sudha_format( fname):\n",
    "    model = dict();\n",
    "    f = open( fname, 'r');\n",
    "    lcnt = 0;\n",
    "    for line in f:\n",
    "        if lcnt == 0:\n",
    "            lcnt += 1;\n",
    "            continue;\n",
    "        tokens = line.strip().split( ' ');\n",
    "        key = tokens[ 0];\n",
    "        val = np.asarray( [ float( token) for token in tokens[ 1:]]);\n",
    "        word, pos, sid = key.split( '@');\n",
    "        if pos == 'noun':\n",
    "            pos = 'n';\n",
    "        if pos == 'adjective':\n",
    "            pos = 'a';\n",
    "        if pos == 'verb':\n",
    "            pos = 'v';\n",
    "        if pos == 'adverb':\n",
    "            pos = 'r';\n",
    "        mkey = sid + '_' + pos;\n",
    "        model[ mkey] = val;\n",
    "    return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hin_read_sudha_format( fname):\n",
    "    model = dict();\n",
    "    f = open( fname, 'r');\n",
    "    lcnt = 0;\n",
    "    for line in f:\n",
    "        if lcnt == 0:\n",
    "            lcnt += 1;\n",
    "            continue;\n",
    "        tokens = line.strip().split( ' ');\n",
    "        key = tokens[ 0];\n",
    "        val = np.asarray( [ float( token) for token in tokens[ 1:]]);\n",
    "        word, sid = key.split( '@');\n",
    "        mkey = sid;\n",
    "        model[ mkey] = val;\n",
    "    return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_pos_to_hin( model):\n",
    "    ret_model = dict();\n",
    "    adjs = [];\n",
    "    advs = [];\n",
    "    nouns = [];\n",
    "    verbs = [];\n",
    "    f = open( fprefix + 'adj.idx', 'r');\n",
    "    for line in f:\n",
    "        adjs.append( line.strip());\n",
    "    f.close();\n",
    "    f = open( fprefix + 'adv.idx', 'r');\n",
    "    for line in f:\n",
    "        advs.append( line.strip());\n",
    "    f.close();\n",
    "    f = open( fprefix + 'noun.idx', 'r');\n",
    "    for line in f:\n",
    "        nouns.append( line.strip());\n",
    "    f.close();\n",
    "    f = open( fprefix + 'verb.idx', 'r');\n",
    "    for line in f:\n",
    "        verbs.append( line.strip());\n",
    "    f.close();\n",
    "    for key in model:\n",
    "        if key in adjs:\n",
    "            mkey = key + '_a';\n",
    "        if key in advs:\n",
    "            mkey = key + '_r';\n",
    "        if key in nouns:\n",
    "            mkey = key + '_n';\n",
    "        if key in verbs:\n",
    "            mkey = key + '_v';\n",
    "        ret_model[ mkey] = model[ key];\n",
    "    return ret_model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fprefix = '/home/development/kevin/workspace/linking/data/';\n",
    "fname = fprefix + 'english-sense-vector_sb.txt';\n",
    "eng_m = eng_read_sudha_format( fname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_remove = [];\n",
    "for key in eng_m:\n",
    "    val = eng_m[ key];\n",
    "    if np.linalg.norm( val) < 1e-6:\n",
    "        to_remove.append( key);\n",
    "for elem in to_remove:\n",
    "    del eng_m[ elem];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print( type( eng_m[ '2430830_n']));\n",
    "print( len( eng_m[ '2430830_n']));\n",
    "print( np.shape( eng_m[ '2430830_n']));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fname = fprefix + 'hindi-sense-vector_sb.txt';\n",
    "fname = fprefix + 'hindi_cbow_300_5_10_sense.txt';\n",
    "hin_m = hin_read_sudha_format( fname);\n",
    "hin_m = add_pos_to_hin( hin_m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "300\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print( type( hin_m[ '16074_n']));\n",
    "print( len( hin_m[ '16074_n']));\n",
    "print( np.shape( hin_m[ '16074_n']));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hin_dict = dict();\n",
    "eng_dict = dict();\n",
    "pos_list = [ 'a', 'n', 'r', 'v'];\n",
    "for pos in pos_list:\n",
    "    hin_dict[ pos] = dict();\n",
    "    eng_dict[ pos] = dict();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in hin_m:\n",
    "    if 'a' in key:\n",
    "        hin_dict[ 'a'][ key] = hin_m[ key];\n",
    "    if 'n' in key:\n",
    "        hin_dict[ 'n'][ key] = hin_m[ key];\n",
    "    if 'r' in key:\n",
    "        hin_dict[ 'r'][ key] = hin_m[ key];\n",
    "    if 'v' in key:\n",
    "        hin_dict[ 'v'][ key] = hin_m[ key];\n",
    "\n",
    "for key in eng_m:\n",
    "    if 'a' in key:\n",
    "        eng_dict[ 'a'][ key] = eng_m[ key];\n",
    "    if 'n' in key:\n",
    "        eng_dict[ 'n'][ key] = eng_m[ key];\n",
    "    if 'r' in key:\n",
    "        eng_dict[ 'r'][ key] = eng_m[ key];\n",
    "    if 'v' in key:\n",
    "        eng_dict[ 'v'][ key] = eng_m[ key];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hlist = dict();\n",
    "elist = dict();\n",
    "link_list = [];\n",
    "fname = fprefix + 'links.csv';\n",
    "f = open( fname, 'r');\n",
    "mcnt = 0; # number of direct links which are mismatch in pos\n",
    "tcnt = 0;\n",
    "cnt_dict = dict();\n",
    "for line in f:\n",
    "    tokens = line.strip().split( ',');\n",
    "    if tokens[ 1] == 'ADJECTIVE':\n",
    "        p1 = 'a';\n",
    "    if tokens[ 1] == 'NOUN':\n",
    "        p1 = 'n';\n",
    "    if tokens[ 1] == 'VERB':\n",
    "        p1 = 'v';\n",
    "    if tokens[ 1] == 'ADVERB':\n",
    "        p1 == 'r';\n",
    "    if tokens[ 3] == 'ADJECTIVE':\n",
    "        p2 = 'a';\n",
    "    if tokens[ 3] == 'NOUN':\n",
    "        p2 = 'n';\n",
    "    if tokens[ 3] == 'VERB':\n",
    "        p2 = 'v';\n",
    "    if tokens[ 3] == 'ADVERB':\n",
    "        p2 == 'r';\n",
    "    k1 = tokens[ 0] + '_' + p1;\n",
    "    k2 = tokens[ 2] + '_' + p2;\n",
    "    if p1 != p2:\n",
    "        mcnt += 1;\n",
    "    else:\n",
    "        if p1 not in cnt_dict:\n",
    "            cnt_dict[ p1] = 0;\n",
    "        cnt_dict[ p1] += 1\n",
    "        link_list.append( ( k1, k2, p1));\n",
    "    tcnt += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "3602\n",
      "11709\n",
      "2003\n",
      "17325\n"
     ]
    }
   ],
   "source": [
    "print( mcnt);\n",
    "print( cnt_dict[ 'a']);\n",
    "print( cnt_dict[ 'n']);\n",
    "print( cnt_dict[ 'v']);\n",
    "print( tcnt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17314\n"
     ]
    }
   ],
   "source": [
    "print( len( link_list));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8398\n",
      "0\n",
      "7064\n",
      "1334\n"
     ]
    }
   ],
   "source": [
    "avail_list = [];\n",
    "avail_dict = dict();\n",
    "for tup in link_list:\n",
    "    k1, k2, pos = tup;\n",
    "    if pos not in avail_dict:\n",
    "        avail_dict[ pos] = [];\n",
    "    if k1 not in hin_m:\n",
    "        continue;\n",
    "    if k2 not in eng_m:\n",
    "        continue;\n",
    "    avail_list.append( tup);\n",
    "    avail_dict[ pos].append( tup);\n",
    "print( len( avail_list));\n",
    "for key in avail_dict:\n",
    "    print( len( avail_dict[ key]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['a', 'r', 'n', 'v'])\n",
      "dict_keys(['a', 'r', 'n', 'v'])\n",
      "dict_keys(['a', 'r', 'n', 'v'])\n",
      "a 0\n",
      "r 0\n",
      "n 7064\n",
      "v 1334\n"
     ]
    }
   ],
   "source": [
    "avail_dict[ 'r'] = [];\n",
    "print( avail_dict.keys());\n",
    "print( eng_dict.keys());\n",
    "print( hin_dict.keys());\n",
    "for key in avail_dict:\n",
    "    print( key, len( avail_dict[ key]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_h2e( train_list, inp_m, out_m, bias_p = False):\n",
    "    ivlist = [];\n",
    "    ovlist = [];\n",
    "    for tup in train_list:\n",
    "        k1, k2, pos = tup;\n",
    "        ivlist.append( inp_m[ k1]);\n",
    "        ovlist.append( out_m[ k2]);\n",
    "    i_data = np.asarray( ivlist, dtype = 'f4');\n",
    "    o_data = np.asarray( ovlist, dtype = 'f4');\n",
    "    dim = len( o_data[ 0]);\n",
    "    #print( dim);\n",
    "    dmodel_list = [];\n",
    "    print( 'Training', flush = True);\n",
    "    for i in range( dim):\n",
    "        #print( 'Dim = ', i, flush = True);\n",
    "        X = i_data;\n",
    "        Y = o_data[ :, i];\n",
    "        cur_model = LinearRegression( fit_intercept = bias_p);\n",
    "        cur_model.fit( X, Y);\n",
    "        dmodel_list.append( cur_model);\n",
    "    return dmodel_list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_model( test_list, inp_m, out_m, model_list):\n",
    "    ivlist = [];\n",
    "    ovlist = [];\n",
    "    for tup in test_list:\n",
    "        k1, k2, pos = tup;\n",
    "        ivlist.append( inp_m[ k1]);\n",
    "        ovlist.append( out_m[ k2]);\n",
    "    i_data = np.array( ivlist, dtype = 'f4');\n",
    "    dim = len( ovlist[ 0]);\n",
    "    ypred = [];\n",
    "    print( 'Translating', flush = True);\n",
    "    for i in range( dim):\n",
    "        #print( 'Dim = ', i, flush = True);\n",
    "        X = i_data;\n",
    "        cur_model = model_list[ i];\n",
    "        Yp = cur_model.predict( X);\n",
    "        ypred.append( Yp);\n",
    "    pred_data = ypred[ 0];\n",
    "    for i in range( 1, dim):\n",
    "        pred_data = np.column_stack( ( pred_data, ypred[ i]));\n",
    "    #print( np.shape( pred_data));\n",
    "    return pred_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_acc( test_list, inp_m, out_m, pred_data):\n",
    "    print( 'Sim Scoring', flush = True);\n",
    "    ivlist = [];\n",
    "    ovlist = [];\n",
    "    ptr = 0;\n",
    "    k2id = dict();\n",
    "    id2k = dict();\n",
    "    for key in out_m:\n",
    "        ovlist.append( out_m[ key]);\n",
    "        k2id[ key] = ptr;\n",
    "        id2k[ ptr] = key;\n",
    "        ptr += 1;\n",
    "    o_data = np.asarray( ovlist, dtype = 'f4');\n",
    "    no_data = ( o_data.T / np.linalg.norm( o_data, axis = 1)).T;\n",
    "    npred_data = ( pred_data.T / np.linalg.norm( pred_data, axis = 1)).T;\n",
    "    sim_mat = npred_data.dot( no_data.T);\n",
    "    r, c = np.shape( sim_mat);\n",
    "    #trim_sim_mat = np.sort( sim_mat)[ :, ::-1];\n",
    "    trim_ind_mat = np.argsort( sim_mat)[ :, ::-1];\n",
    "    indx = [];\n",
    "    posl = [];\n",
    "    print( 'Ranking', flush = True);\n",
    "    for i in range( r):\n",
    "        true = test_list[ i][ 1];\n",
    "        pos = test_list[ i][ 2];\n",
    "        tlist = trim_ind_mat[ i].tolist();\n",
    "        tind = tlist.index( k2id[ true]);\n",
    "        indx.append( tind);\n",
    "        posl.append( pos);\n",
    "    acc_01 = sum( [ elem < 1 for elem in indx]);\n",
    "    acc_03 = sum( [ elem < 3 for elem in indx]);\n",
    "    acc_05 = sum( [ elem < 5 for elem in indx]);\n",
    "    acc_08 = sum( [ elem < 8 for elem in indx]);\n",
    "    acc_10 = sum( [ elem < 10 for elem in indx]);\n",
    "    acc_20 = sum( [ elem < 20 for elem in indx]);\n",
    "    acc_50 = sum( [ elem < 50 for elem in indx]);\n",
    "    acc_100 = sum( [ elem < 100 for elem in indx]);\n",
    "    print( acc_01 / len( indx));\n",
    "    print( acc_03 / len( indx));\n",
    "    print( acc_05 / len( indx));\n",
    "    print( acc_08 / len( indx));\n",
    "    print( acc_10 / len( indx));\n",
    "    print( acc_20 / len( indx));\n",
    "    print( acc_50 / len( indx));\n",
    "    print( acc_100 / len( indx));\n",
    "    print( min( indx), max( indx), len( indx));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation( link_list, inp_m, out_m, bias_p = False):\n",
    "    fold_beg = [ 0] * 10;\n",
    "    fold_end = [ 0] * 10;\n",
    "    for i in range( 1, 10):\n",
    "        fold_end[ i - 1] = (len( link_list) // 10) * i;\n",
    "        fold_beg[ i] = (len( link_list) // 10) * i;\n",
    "    fold_end[ 9] = len( link_list);\n",
    "    for fold_ptr in range( 10):\n",
    "        print( 'Running fold ', fold_ptr, flush = True);\n",
    "        train_list = [];\n",
    "        test_list = [];\n",
    "        for i in range( 10):\n",
    "            if i != fold_ptr:\n",
    "                train_list.extend( link_list[ fold_beg[ i] : fold_end[ i]]);\n",
    "            else:\n",
    "                test_list.extend( link_list[ fold_beg[ i] : fold_end[ i]]);\n",
    "        dmodel_list = train_h2e( train_list, inp_m, out_m, bias_p);\n",
    "        pred_data = apply_model( test_list, inp_m, out_m, dmodel_list);\n",
    "        get_acc( test_list, inp_m, out_m, pred_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold  0\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.022556390977443608\n",
      "0.045112781954887216\n",
      "0.06766917293233082\n",
      "0.09022556390977443\n",
      "0.16541353383458646\n",
      "0.21052631578947367\n",
      "0.3157894736842105\n",
      "0.3684210526315789\n",
      "0 11255 133\n",
      "Running fold  1\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.045112781954887216\n",
      "0.08270676691729323\n",
      "0.11278195488721804\n",
      "0.17293233082706766\n",
      "0.20300751879699247\n",
      "0.2781954887218045\n",
      "0.3458646616541353\n",
      "0.38345864661654133\n",
      "0 8024 133\n",
      "Running fold  2\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.045112781954887216\n",
      "0.13533834586466165\n",
      "0.17293233082706766\n",
      "0.21804511278195488\n",
      "0.23308270676691728\n",
      "0.2781954887218045\n",
      "0.3458646616541353\n",
      "0.42857142857142855\n",
      "0 9805 133\n",
      "Running fold  3\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.07518796992481203\n",
      "0.11278195488721804\n",
      "0.12781954887218044\n",
      "0.17293233082706766\n",
      "0.18796992481203006\n",
      "0.2631578947368421\n",
      "0.3609022556390977\n",
      "0.41353383458646614\n",
      "0 11156 133\n",
      "Running fold  4\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.06015037593984962\n",
      "0.13533834586466165\n",
      "0.17293233082706766\n",
      "0.24060150375939848\n",
      "0.24060150375939848\n",
      "0.2932330827067669\n",
      "0.3684210526315789\n",
      "0.44360902255639095\n",
      "0 11065 133\n",
      "Running fold  5\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.06766917293233082\n",
      "0.14285714285714285\n",
      "0.15789473684210525\n",
      "0.17293233082706766\n",
      "0.18796992481203006\n",
      "0.2556390977443609\n",
      "0.3383458646616541\n",
      "0.42105263157894735\n",
      "0 9922 133\n",
      "Running fold  6\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.05263157894736842\n",
      "0.07518796992481203\n",
      "0.10526315789473684\n",
      "0.14285714285714285\n",
      "0.18045112781954886\n",
      "0.23308270676691728\n",
      "0.3233082706766917\n",
      "0.37593984962406013\n",
      "0 10453 133\n",
      "Running fold  7\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.03007518796992481\n",
      "0.06015037593984962\n",
      "0.08270676691729323\n",
      "0.10526315789473684\n",
      "0.12030075187969924\n",
      "0.18045112781954886\n",
      "0.2781954887218045\n",
      "0.3533834586466165\n",
      "0 9871 133\n",
      "Running fold  8\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.022556390977443608\n",
      "0.08270676691729323\n",
      "0.09022556390977443\n",
      "0.10526315789473684\n",
      "0.12030075187969924\n",
      "0.14285714285714285\n",
      "0.19548872180451127\n",
      "0.21804511278195488\n",
      "0 9224 133\n",
      "Running fold  9\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.051094890510948905\n",
      "0.08759124087591241\n",
      "0.12408759124087591\n",
      "0.1386861313868613\n",
      "0.15328467153284672\n",
      "0.21897810218978103\n",
      "0.31386861313868614\n",
      "0.38686131386861317\n",
      "0 10959 137\n"
     ]
    }
   ],
   "source": [
    "cross_validation( avail_dict[ 'v'], hin_dict[ 'v'], eng_dict[ 'v']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold  0\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.13739376770538245\n",
      "0.2577903682719547\n",
      "0.3314447592067989\n",
      "0.38526912181303113\n",
      "0.40368271954674223\n",
      "0.4985835694050991\n",
      "0.5694050991501416\n",
      "0.6444759206798867\n",
      "0 24950 706\n",
      "Running fold  1\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.12889518413597734\n",
      "0.24504249291784702\n",
      "0.311614730878187\n",
      "0.3640226628895184\n",
      "0.3838526912181303\n",
      "0.47592067988668557\n",
      "0.5524079320113314\n",
      "0.6288951841359773\n",
      "0 25960 706\n",
      "Running fold  2\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.08923512747875353\n",
      "0.17847025495750707\n",
      "0.23654390934844194\n",
      "0.28753541076487255\n",
      "0.3101983002832861\n",
      "0.3881019830028329\n",
      "0.4971671388101983\n",
      "0.5821529745042493\n",
      "0 26198 706\n",
      "Running fold  3\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.09490084985835694\n",
      "0.21246458923512748\n",
      "0.29036827195467424\n",
      "0.3555240793201133\n",
      "0.37677053824362605\n",
      "0.4546742209631728\n",
      "0.5354107648725213\n",
      "0.6189801699716714\n",
      "0 27737 706\n",
      "Running fold  4\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.1388101983002833\n",
      "0.2563739376770538\n",
      "0.3130311614730878\n",
      "0.3810198300283286\n",
      "0.40226628895184136\n",
      "0.49291784702549574\n",
      "0.5878186968838527\n",
      "0.6487252124645893\n",
      "0 25664 706\n",
      "Running fold  5\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.14730878186968838\n",
      "0.2507082152974504\n",
      "0.3002832861189802\n",
      "0.3696883852691218\n",
      "0.39660056657223797\n",
      "0.46742209631728043\n",
      "0.5509915014164306\n",
      "0.6373937677053825\n",
      "0 25972 706\n",
      "Running fold  6\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.14022662889518414\n",
      "0.2705382436260623\n",
      "0.34702549575070823\n",
      "0.39943342776203966\n",
      "0.4206798866855524\n",
      "0.49575070821529743\n",
      "0.5949008498583569\n",
      "0.6671388101983002\n",
      "0 24439 706\n",
      "Running fold  7\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.09490084985835694\n",
      "0.16572237960339944\n",
      "0.23087818696883852\n",
      "0.29036827195467424\n",
      "0.31586402266288954\n",
      "0.39943342776203966\n",
      "0.509915014164306\n",
      "0.5708215297450425\n",
      "0 28035 706\n",
      "Running fold  8\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.08356940509915015\n",
      "0.1954674220963173\n",
      "0.24504249291784702\n",
      "0.2847025495750708\n",
      "0.3073654390934844\n",
      "0.3597733711048159\n",
      "0.4348441926345609\n",
      "0.4830028328611898\n",
      "0 26165 706\n",
      "Running fold  9\n",
      "Training\n",
      "Translating\n",
      "Sim Scoring\n",
      "Ranking\n",
      "0.1352112676056338\n",
      "0.271830985915493\n",
      "0.3464788732394366\n",
      "0.4056338028169014\n",
      "0.428169014084507\n",
      "0.49014084507042255\n",
      "0.5676056338028169\n",
      "0.6225352112676056\n",
      "0 27434 710\n"
     ]
    }
   ],
   "source": [
    "cross_validation( avail_dict[ 'n'], hin_dict[ 'n'], eng_dict[ 'n']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def h2e( train_list, test_list, bias_p = False):\n",
    "    evlist = [];\n",
    "    hvlist = [];\n",
    "    for tup in train_list:\n",
    "        k1, k2, pos = tup;\n",
    "        hvlist.append( hin_m[ k1]);\n",
    "        evlist.append( eng_m[ k2]);\n",
    "    h_data = np.array( hvlist, dtype = 'f4');\n",
    "    e_data = np.array( evlist, dtype = 'f4');\n",
    "    dim = len( e_data[ 0]);\n",
    "    print( dim);\n",
    "    dmodel_list = [];\n",
    "    print( 'Training', flush = True);\n",
    "    for i in range( dim):\n",
    "        print( 'Dim = ', i, flush = True);\n",
    "        X = h_data;\n",
    "        Y = e_data[ :, i];\n",
    "        cur_model = LinearRegression( fit_intercept = bias_p);\n",
    "        cur_model.fit( X, Y);\n",
    "        dmodel_list.append( cur_model);\n",
    "    evlist = [];\n",
    "    hvlist = [];\n",
    "    for tup in test_list:\n",
    "        k1, k2, pos = tup;\n",
    "        hvlist.append( hin_m[ k1]);\n",
    "        evlist.append( eng_m[ k2]);\n",
    "    inp_data = np.array( hvlist, dtype = 'f4');\n",
    "    \n",
    "    ypred = [];\n",
    "    print( 'Translating', flush = True);\n",
    "    for i in range( dim):\n",
    "        print( 'Dim = ', i, flush = True);\n",
    "        X = inp_data;\n",
    "        cur_model = dmodel_list[ i];\n",
    "        Yp = cur_model.predict( X);\n",
    "        ypred.append( Yp);\n",
    "    trans_syn_data = ypred[ 0];\n",
    "    for i in range( 1, dim):\n",
    "        trans_syn_data = np.column_stack( ( trans_syn_data, ypred[ i]));\n",
    "    print( np.shape( trans_syn_data));\n",
    "    evlist = [];\n",
    "    hvlist = [];\n",
    "    ptr = 0;\n",
    "    k2id = dict();\n",
    "    id2k = dict();\n",
    "    for key in eng_m:\n",
    "        evlist.append( eng_m[ key]);\n",
    "        k2id[ key] = ptr;\n",
    "        id2k[ ptr] = key;\n",
    "        ptr += 1;\n",
    "    e_data = np.asarray( evlist, dtype = 'f4');\n",
    "    print( np.shape( e_data));\n",
    "    \n",
    "    ntrans_syn_data = ( trans_syn_data.T / np.linalg.norm( trans_syn_data, axis = 1)).T;\n",
    "    ne_data = ( e_data.T / np.linalg.norm( e_data, axis = 1)).T;\n",
    "    print( np.shape( trans_syn_data));\n",
    "    print( np.shape( ntrans_syn_data));\n",
    "    print( np.shape( e_data));\n",
    "    print( np.shape( ne_data));\n",
    "    \n",
    "    sim_mat = ntrans_syn_data.dot( ne_data.T);\n",
    "    print( np.shape( sim_mat));\n",
    "    r, c = np.shape( sim_mat);\n",
    "    trim_sim_mat = np.sort( sim_mat)[ :, ::-1];\n",
    "    trim_ind_mat = np.argsort( sim_mat)[ :, ::-1];\n",
    "    \n",
    "    print( np.shape( trim_sim_mat));\n",
    "    print( np.shape( trim_ind_mat));\n",
    "    \n",
    "    indx = [];\n",
    "    posl = [];\n",
    "    for i in range( r):\n",
    "        true = test_list[ i][ 1];\n",
    "        pos = test_list[ i][ 2];\n",
    "        tlist = trim_ind_mat[ i].tolist();\n",
    "        cur_pos = 0;\n",
    "        pos_pos = 0;\n",
    "        for item in tlist:\n",
    "            if k2id[ true] == item:\n",
    "                break\n",
    "            if pos in id2k[ item]:\n",
    "                pos_pos += 1;\n",
    "        #tind = tlist.index( k2id[ true]);\n",
    "        indx.append( pos_pos);\n",
    "        posl.append( pos);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Training\n",
      "Dim =  0\n",
      "Dim =  1\n",
      "Dim =  2\n",
      "Dim =  3\n",
      "Dim =  4\n",
      "Dim =  5\n",
      "Dim =  6\n",
      "Dim =  7\n",
      "Dim =  8\n",
      "Dim =  9\n",
      "Dim =  10\n",
      "Dim =  11\n",
      "Dim =  12\n",
      "Dim =  13\n",
      "Dim =  14\n",
      "Dim =  15\n",
      "Dim =  16\n",
      "Dim =  17\n",
      "Dim =  18\n",
      "Dim =  19\n",
      "Dim =  20\n",
      "Dim =  21\n",
      "Dim =  22\n",
      "Dim =  23\n",
      "Dim =  24\n",
      "Dim =  25\n",
      "Dim =  26\n",
      "Dim =  27\n",
      "Dim =  28\n",
      "Dim =  29\n",
      "Dim =  30\n",
      "Dim =  31\n",
      "Dim =  32\n",
      "Dim =  33\n",
      "Dim =  34\n",
      "Dim =  35\n",
      "Dim =  36\n",
      "Dim =  37\n",
      "Dim =  38\n",
      "Dim =  39\n",
      "Dim =  40\n",
      "Dim =  41\n",
      "Dim =  42\n",
      "Dim =  43\n",
      "Dim =  44\n",
      "Dim =  45\n",
      "Dim =  46\n",
      "Dim =  47\n",
      "Dim =  48\n",
      "Dim =  49\n",
      "Dim =  50\n",
      "Dim =  51\n",
      "Dim =  52\n",
      "Dim =  53\n",
      "Dim =  54\n",
      "Dim =  55\n",
      "Dim =  56\n",
      "Dim =  57\n",
      "Dim =  58\n",
      "Dim =  59\n",
      "Dim =  60\n",
      "Dim =  61\n",
      "Dim =  62\n",
      "Dim =  63\n",
      "Dim =  64\n",
      "Dim =  65\n",
      "Dim =  66\n",
      "Dim =  67\n",
      "Dim =  68\n",
      "Dim =  69\n",
      "Dim =  70\n",
      "Dim =  71\n",
      "Dim =  72\n",
      "Dim =  73\n",
      "Dim =  74\n",
      "Dim =  75\n",
      "Dim =  76\n",
      "Dim =  77\n",
      "Dim =  78\n",
      "Dim =  79\n",
      "Dim =  80\n",
      "Dim =  81\n",
      "Dim =  82\n",
      "Dim =  83\n",
      "Dim =  84\n",
      "Dim =  85\n",
      "Dim =  86\n",
      "Dim =  87\n",
      "Dim =  88\n",
      "Dim =  89\n",
      "Dim =  90\n",
      "Dim =  91\n",
      "Dim =  92\n",
      "Dim =  93\n",
      "Dim =  94\n",
      "Dim =  95\n",
      "Dim =  96\n",
      "Dim =  97\n",
      "Dim =  98\n",
      "Dim =  99\n",
      "Dim =  100\n",
      "Dim =  101\n",
      "Dim =  102\n",
      "Dim =  103\n",
      "Dim =  104\n",
      "Dim =  105\n",
      "Dim =  106\n",
      "Dim =  107\n",
      "Dim =  108\n",
      "Dim =  109\n",
      "Dim =  110\n",
      "Dim =  111\n",
      "Dim =  112\n",
      "Dim =  113\n",
      "Dim =  114\n",
      "Dim =  115\n",
      "Dim =  116\n",
      "Dim =  117\n",
      "Dim =  118\n",
      "Dim =  119\n",
      "Dim =  120\n",
      "Dim =  121\n",
      "Dim =  122\n",
      "Dim =  123\n",
      "Dim =  124\n",
      "Dim =  125\n",
      "Dim =  126\n",
      "Dim =  127\n",
      "Dim =  128\n",
      "Dim =  129\n",
      "Dim =  130\n",
      "Dim =  131\n",
      "Dim =  132\n",
      "Dim =  133\n",
      "Dim =  134\n",
      "Dim =  135\n",
      "Dim =  136\n",
      "Dim =  137\n",
      "Dim =  138\n",
      "Dim =  139\n",
      "Dim =  140\n",
      "Dim =  141\n",
      "Dim =  142\n",
      "Dim =  143\n",
      "Dim =  144\n",
      "Dim =  145\n",
      "Dim =  146\n",
      "Dim =  147\n",
      "Dim =  148\n",
      "Dim =  149\n",
      "Dim =  150\n",
      "Dim =  151\n",
      "Dim =  152\n",
      "Dim =  153\n",
      "Dim =  154\n",
      "Dim =  155\n",
      "Dim =  156\n",
      "Dim =  157\n",
      "Dim =  158\n",
      "Dim =  159\n",
      "Dim =  160\n",
      "Dim =  161\n",
      "Dim =  162\n",
      "Dim =  163\n",
      "Dim =  164\n",
      "Dim =  165\n",
      "Dim =  166\n",
      "Dim =  167\n",
      "Dim =  168\n",
      "Dim =  169\n",
      "Dim =  170\n",
      "Dim =  171\n",
      "Dim =  172\n",
      "Dim =  173\n",
      "Dim =  174\n",
      "Dim =  175\n",
      "Dim =  176\n",
      "Dim =  177\n",
      "Dim =  178\n",
      "Dim =  179\n",
      "Dim =  180\n",
      "Dim =  181\n",
      "Dim =  182\n",
      "Dim =  183\n",
      "Dim =  184\n",
      "Dim =  185\n",
      "Dim =  186\n",
      "Dim =  187\n",
      "Dim =  188\n",
      "Dim =  189\n",
      "Dim =  190\n",
      "Dim =  191\n",
      "Dim =  192\n",
      "Dim =  193\n",
      "Dim =  194\n",
      "Dim =  195\n",
      "Dim =  196\n",
      "Dim =  197\n",
      "Dim =  198\n",
      "Dim =  199\n",
      "Dim =  200\n",
      "Dim =  201\n",
      "Dim =  202\n",
      "Dim =  203\n",
      "Dim =  204\n",
      "Dim =  205\n",
      "Dim =  206\n",
      "Dim =  207\n",
      "Dim =  208\n",
      "Dim =  209\n",
      "Dim =  210\n",
      "Dim =  211\n",
      "Dim =  212\n",
      "Dim =  213\n",
      "Dim =  214\n",
      "Dim =  215\n",
      "Dim =  216\n",
      "Dim =  217\n",
      "Dim =  218\n",
      "Dim =  219\n",
      "Dim =  220\n",
      "Dim =  221\n",
      "Dim =  222\n",
      "Dim =  223\n",
      "Dim =  224\n",
      "Dim =  225\n",
      "Dim =  226\n",
      "Dim =  227\n",
      "Dim =  228\n",
      "Dim =  229\n",
      "Dim =  230\n",
      "Dim =  231\n",
      "Dim =  232\n",
      "Dim =  233\n",
      "Dim =  234\n",
      "Dim =  235\n",
      "Dim =  236\n",
      "Dim =  237\n",
      "Dim =  238\n",
      "Dim =  239\n",
      "Dim =  240\n",
      "Dim =  241\n",
      "Dim =  242\n",
      "Dim =  243\n",
      "Dim =  244\n",
      "Dim =  245\n",
      "Dim =  246\n",
      "Dim =  247\n",
      "Dim =  248\n",
      "Dim =  249\n",
      "Dim =  250\n",
      "Dim =  251\n",
      "Dim =  252\n",
      "Dim =  253\n",
      "Dim =  254\n",
      "Dim =  255\n",
      "Dim =  256\n",
      "Dim =  257\n",
      "Dim =  258\n",
      "Dim =  259\n",
      "Dim =  260\n",
      "Dim =  261\n",
      "Dim =  262\n",
      "Dim =  263\n",
      "Dim =  264\n",
      "Dim =  265\n",
      "Dim =  266\n",
      "Dim =  267\n",
      "Dim =  268\n",
      "Dim =  269\n",
      "Dim =  270\n",
      "Dim =  271\n",
      "Dim =  272\n",
      "Dim =  273\n",
      "Dim =  274\n",
      "Dim =  275\n",
      "Dim =  276\n",
      "Dim =  277\n",
      "Dim =  278\n",
      "Dim =  279\n",
      "Dim =  280\n",
      "Dim =  281\n",
      "Dim =  282\n",
      "Dim =  283\n",
      "Dim =  284\n",
      "Dim =  285\n",
      "Dim =  286\n",
      "Dim =  287\n",
      "Dim =  288\n",
      "Dim =  289\n",
      "Dim =  290\n",
      "Dim =  291\n",
      "Dim =  292\n",
      "Dim =  293\n",
      "Dim =  294\n",
      "Dim =  295\n",
      "Dim =  296\n",
      "Dim =  297\n",
      "Dim =  298\n",
      "Dim =  299\n",
      "Translating\n",
      "Dim =  0\n",
      "Dim =  1\n",
      "Dim =  2\n",
      "Dim =  3\n",
      "Dim =  4\n",
      "Dim =  5\n",
      "Dim =  6\n",
      "Dim =  7\n",
      "Dim =  8\n",
      "Dim =  9\n",
      "Dim =  10\n",
      "Dim =  11\n",
      "Dim =  12\n",
      "Dim =  13\n",
      "Dim =  14\n",
      "Dim =  15\n",
      "Dim =  16\n",
      "Dim =  17\n",
      "Dim =  18\n",
      "Dim =  19\n",
      "Dim =  20\n",
      "Dim =  21\n",
      "Dim =  22\n",
      "Dim =  23\n",
      "Dim =  24\n",
      "Dim =  25\n",
      "Dim =  26\n",
      "Dim =  27\n",
      "Dim =  28\n",
      "Dim =  29\n",
      "Dim =  30\n",
      "Dim =  31\n",
      "Dim =  32\n",
      "Dim =  33\n",
      "Dim =  34\n",
      "Dim =  35\n",
      "Dim =  36\n",
      "Dim =  37\n",
      "Dim =  38\n",
      "Dim =  39\n",
      "Dim =  40\n",
      "Dim =  41\n",
      "Dim =  42\n",
      "Dim =  43\n",
      "Dim =  44\n",
      "Dim =  45\n",
      "Dim =  46\n",
      "Dim =  47\n",
      "Dim =  48\n",
      "Dim =  49\n",
      "Dim =  50\n",
      "Dim =  51\n",
      "Dim =  52\n",
      "Dim =  53\n",
      "Dim =  54\n",
      "Dim =  55\n",
      "Dim =  56\n",
      "Dim =  57\n",
      "Dim =  58\n",
      "Dim =  59\n",
      "Dim =  60\n",
      "Dim =  61\n",
      "Dim =  62\n",
      "Dim =  63\n",
      "Dim =  64\n",
      "Dim =  65\n",
      "Dim =  66\n",
      "Dim =  67\n",
      "Dim =  68\n",
      "Dim =  69\n",
      "Dim =  70\n",
      "Dim =  71\n",
      "Dim =  72\n",
      "Dim =  73\n",
      "Dim =  74\n",
      "Dim =  75\n",
      "Dim =  76\n",
      "Dim =  77\n",
      "Dim =  78\n",
      "Dim =  79\n",
      "Dim =  80\n",
      "Dim =  81\n",
      "Dim =  82\n",
      "Dim =  83\n",
      "Dim =  84\n",
      "Dim =  85\n",
      "Dim =  86\n",
      "Dim =  87\n",
      "Dim =  88\n",
      "Dim =  89\n",
      "Dim =  90\n",
      "Dim =  91\n",
      "Dim =  92\n",
      "Dim =  93\n",
      "Dim =  94\n",
      "Dim =  95\n",
      "Dim =  96\n",
      "Dim =  97\n",
      "Dim =  98\n",
      "Dim =  99\n",
      "Dim =  100\n",
      "Dim =  101\n",
      "Dim =  102\n",
      "Dim =  103\n",
      "Dim =  104\n",
      "Dim =  105\n",
      "Dim =  106\n",
      "Dim =  107\n",
      "Dim =  108\n",
      "Dim =  109\n",
      "Dim =  110\n",
      "Dim =  111\n",
      "Dim =  112\n",
      "Dim =  113\n",
      "Dim =  114\n",
      "Dim =  115\n",
      "Dim =  116\n",
      "Dim =  117\n",
      "Dim =  118\n",
      "Dim =  119\n",
      "Dim =  120\n",
      "Dim =  121\n",
      "Dim =  122\n",
      "Dim =  123\n",
      "Dim =  124\n",
      "Dim =  125\n",
      "Dim =  126\n",
      "Dim =  127\n",
      "Dim =  128\n",
      "Dim =  129\n",
      "Dim =  130\n",
      "Dim =  131\n",
      "Dim =  132\n",
      "Dim =  133\n",
      "Dim =  134\n",
      "Dim =  135\n",
      "Dim =  136\n",
      "Dim =  137\n",
      "Dim =  138\n",
      "Dim =  139\n",
      "Dim =  140\n",
      "Dim =  141\n",
      "Dim =  142\n",
      "Dim =  143\n",
      "Dim =  144\n",
      "Dim =  145\n",
      "Dim =  146\n",
      "Dim =  147\n",
      "Dim =  148\n",
      "Dim =  149\n",
      "Dim =  150\n",
      "Dim =  151\n",
      "Dim =  152\n",
      "Dim =  153\n",
      "Dim =  154\n",
      "Dim =  155\n",
      "Dim =  156\n",
      "Dim =  157\n",
      "Dim =  158\n",
      "Dim =  159\n",
      "Dim =  160\n",
      "Dim =  161\n",
      "Dim =  162\n",
      "Dim =  163\n",
      "Dim =  164\n",
      "Dim =  165\n",
      "Dim =  166\n",
      "Dim =  167\n",
      "Dim =  168\n",
      "Dim =  169\n",
      "Dim =  170\n",
      "Dim =  171\n",
      "Dim =  172\n",
      "Dim =  173\n",
      "Dim =  174\n",
      "Dim =  175\n",
      "Dim =  176\n",
      "Dim =  177\n",
      "Dim =  178\n",
      "Dim =  179\n",
      "Dim =  180\n",
      "Dim =  181\n",
      "Dim =  182\n",
      "Dim =  183\n",
      "Dim =  184\n",
      "Dim =  185\n",
      "Dim =  186\n",
      "Dim =  187\n",
      "Dim =  188\n",
      "Dim =  189\n",
      "Dim =  190\n",
      "Dim =  191\n",
      "Dim =  192\n",
      "Dim =  193\n",
      "Dim =  194\n",
      "Dim =  195\n",
      "Dim =  196\n",
      "Dim =  197\n",
      "Dim =  198\n",
      "Dim =  199\n",
      "Dim =  200\n",
      "Dim =  201\n",
      "Dim =  202\n",
      "Dim =  203\n",
      "Dim =  204\n",
      "Dim =  205\n",
      "Dim =  206\n",
      "Dim =  207\n",
      "Dim =  208\n",
      "Dim =  209\n",
      "Dim =  210\n",
      "Dim =  211\n",
      "Dim =  212\n",
      "Dim =  213\n",
      "Dim =  214\n",
      "Dim =  215\n",
      "Dim =  216\n",
      "Dim =  217\n",
      "Dim =  218\n",
      "Dim =  219\n",
      "Dim =  220\n",
      "Dim =  221\n",
      "Dim =  222\n",
      "Dim =  223\n",
      "Dim =  224\n",
      "Dim =  225\n",
      "Dim =  226\n",
      "Dim =  227\n",
      "Dim =  228\n",
      "Dim =  229\n",
      "Dim =  230\n",
      "Dim =  231\n",
      "Dim =  232\n",
      "Dim =  233\n",
      "Dim =  234\n",
      "Dim =  235\n",
      "Dim =  236\n",
      "Dim =  237\n",
      "Dim =  238\n",
      "Dim =  239\n",
      "Dim =  240\n",
      "Dim =  241\n",
      "Dim =  242\n",
      "Dim =  243\n",
      "Dim =  244\n",
      "Dim =  245\n",
      "Dim =  246\n",
      "Dim =  247\n",
      "Dim =  248\n",
      "Dim =  249\n",
      "Dim =  250\n",
      "Dim =  251\n",
      "Dim =  252\n",
      "Dim =  253\n",
      "Dim =  254\n",
      "Dim =  255\n",
      "Dim =  256\n",
      "Dim =  257\n",
      "Dim =  258\n",
      "Dim =  259\n",
      "Dim =  260\n",
      "Dim =  261\n",
      "Dim =  262\n",
      "Dim =  263\n",
      "Dim =  264\n",
      "Dim =  265\n",
      "Dim =  266\n",
      "Dim =  267\n",
      "Dim =  268\n",
      "Dim =  269\n",
      "Dim =  270\n",
      "Dim =  271\n",
      "Dim =  272\n",
      "Dim =  273\n",
      "Dim =  274\n",
      "Dim =  275\n",
      "Dim =  276\n",
      "Dim =  277\n",
      "Dim =  278\n",
      "Dim =  279\n",
      "Dim =  280\n",
      "Dim =  281\n",
      "Dim =  282\n",
      "Dim =  283\n",
      "Dim =  284\n",
      "Dim =  285\n",
      "Dim =  286\n",
      "Dim =  287\n",
      "Dim =  288\n",
      "Dim =  289\n",
      "Dim =  290\n",
      "Dim =  291\n",
      "Dim =  292\n",
      "Dim =  293\n",
      "Dim =  294\n",
      "Dim =  295\n",
      "Dim =  296\n",
      "Dim =  297\n",
      "Dim =  298\n",
      "Dim =  299\n",
      "(8398, 300)\n",
      "(48358, 300)\n",
      "(8398, 300)\n",
      "(8398, 300)\n",
      "(48358, 300)\n",
      "(48358, 300)\n",
      "(8398, 48358)\n",
      "(8398, 48358)\n",
      "(8398, 48358)\n"
     ]
    }
   ],
   "source": [
    "#trans_syn_data = h2e( avail_list[ : 841 * 9], avail_list[ 841 * 9:]);\n",
    "#trans_syn_data = h2e( avail_list[ : 841 * 9], avail_list[ 841 * 9:], bias_p = True);\n",
    "#trans_syn_data = h2e( avail_list, avail_list);\n",
    "trans_syn_data = h2e( avail_list, avail_list, bias_p = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking\n",
      "()\n",
      "(48358, 300)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-21e41cdc6c87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0me_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mntrans_syn_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mtrans_syn_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrans_syn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mne_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0me_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0me_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrans_syn_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "import pickle;\n",
    "\n",
    "print( 'Ranking', flush = True);\n",
    "\n",
    "test_list = avail_list;\n",
    "#test_list = avail_list[ 841 * 9:];\n",
    "\n",
    "\n",
    "print( np.shape( trans_syn_data));\n",
    "evlist = [];\n",
    "hvlist = [];\n",
    "ptr = 0;\n",
    "k2id = dict();\n",
    "id2k = dict();\n",
    "for key in eng_m:\n",
    "    evlist.append( eng_m[ key]);\n",
    "    k2id[ key] = ptr;\n",
    "    id2k[ ptr] = key;\n",
    "    ptr += 1;\n",
    "e_data = np.asarray( evlist, dtype = 'f4');\n",
    "print( np.shape( e_data));\n",
    "\n",
    "ntrans_syn_data = ( trans_syn_data.T / np.linalg.norm( trans_syn_data, axis = 1)).T;\n",
    "ne_data = ( e_data.T / np.linalg.norm( e_data, axis = 1)).T;\n",
    "print( np.shape( trans_syn_data));\n",
    "print( np.shape( ntrans_syn_data));\n",
    "print( np.shape( e_data));\n",
    "print( np.shape( ne_data));\n",
    "\n",
    "sim_mat = ntrans_syn_data.dot( ne_data.T);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print( np.shape( sim_mat));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r, c = np.shape( sim_mat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trim_sim_mat = np.sort( sim_mat)[ :, ::-1]\n",
    "trim_ind_mat = np.argsort( sim_mat)[ :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print( np.shape( trim_sim_mat));\n",
    "print( np.shape( trim_ind_mat));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indx = [];\n",
    "posl = [];\n",
    "for i in range( r):\n",
    "    true = test_list[ i][ 1];\n",
    "    pos = test_list[ i][ 2];\n",
    "    tlist = trim_ind_mat[ i].tolist();\n",
    "    cur_pos = 0;\n",
    "    pos_pos = 0;\n",
    "    for item in tlist:\n",
    "        if k2id[ true] == item:\n",
    "            break\n",
    "        if pos in id2k[ item]:\n",
    "            pos_pos += 1;\n",
    "    #tind = tlist.index( k2id[ true]);\n",
    "    indx.append( pos_pos);\n",
    "    posl.append( pos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_01 = sum( [ elem < 1 for elem in indx]);\n",
    "acc_03 = sum( [ elem < 3 for elem in indx]);\n",
    "acc_05 = sum( [ elem < 5 for elem in indx]);\n",
    "acc_08 = sum( [ elem < 8 for elem in indx]);\n",
    "acc_10 = sum( [ elem < 10 for elem in indx]);\n",
    "acc_20 = sum( [ elem < 20 for elem in indx]);\n",
    "acc_50 = sum( [ elem < 50 for elem in indx]);\n",
    "acc_100 = sum( [ elem < 100 for elem in indx]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print( acc_01 / len( avail_list));\n",
    "print( acc_03 / len( avail_list));\n",
    "print( acc_05 / len( avail_list));\n",
    "print( acc_08 / len( avail_list));\n",
    "print( acc_10 / len( avail_list));\n",
    "print( acc_20 / len( avail_list));\n",
    "print( acc_50 / len( avail_list));\n",
    "print( acc_100 / len( avail_list));\n",
    "print( min( indx), max( indx), len( indx));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('33093', '14377617_n', 'n'), ('33140', '9862345_n', 'n'), ('33154', '2964634_n', 'n'), ('33269', '839778_n', 'n'), ('33273', '331102_n', 'n'), ('33508', '3956157_n', 'n'), ('33550', '13667643_n', 'n'), ('33595', '14941407_n', 'n'), ('33664', '11502102_n', 'n'), ('33684', '1067070_n', 'n')]\n",
      "[[46331 18950 20428 ..., 43673 38788 36346]\n",
      " [48396 16127 16136 ..., 32260 32259     0]\n",
      " [48396 16127 16136 ..., 32260 32259     0]\n",
      " ..., \n",
      " [48396 16127 16136 ..., 32260 32259     0]\n",
      " [48396 16127 16136 ..., 32260 32259     0]\n",
      " [19661 16982 21814 ..., 13461 12002 22947]]\n"
     ]
    }
   ],
   "source": [
    "print( test_list[ : 10]);\n",
    "print( trim_ind_mat[ : 10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 1]\n",
      " [3 2 1]\n",
      " [3 2 1]]\n",
      "[[1 2 0]\n",
      " [1 0 2]\n",
      " [0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "print( np.sort( tp)[ :, ::-1]);\n",
    "print( np.argsort( tp)[ :, ::-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 1]\n",
      " [3 2 1]\n",
      " [3 2 1]]\n"
     ]
    }
   ],
   "source": [
    "x = np.sort( tp)[ :,:: -1];\n",
    "print( x) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "zecnt = 0;\n",
    "for key in eng_m:\n",
    "    val = eng_m[ key];\n",
    "    if np.linalg.norm( val) < 1e-6:\n",
    "        zecnt += 1;\n",
    "print( zecnt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "zhcnt = 0;\n",
    "for key in hin_m:\n",
    "    val = hin_m[ key];\n",
    "    if np.linalg.norm( val) < 1e-15:\n",
    "        zhcnt += 1;\n",
    "print( zhcnt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
