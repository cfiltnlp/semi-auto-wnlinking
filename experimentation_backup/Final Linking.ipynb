{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os;\n",
    "import sys;\n",
    "import numpy as np;\n",
    "from sklearn.linear_model import LinearRegression;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To read synset vectors generated by Sudha's tool\n",
    "def read_sudha_format( fname):\n",
    "    model = dict();\n",
    "    f = open( fname, 'r');\n",
    "    lcnt = 0;\n",
    "    for line in f:\n",
    "        if lcnt == 0:\n",
    "            lcnt += 1;\n",
    "            continue;\n",
    "        tokens = line.strip().split( ' ');\n",
    "        key = tokens[ 0];\n",
    "        val = np.asarray( [ float( token) for token in tokens[ 1:]]);\n",
    "        word, pos, sid = key.split( '@');\n",
    "        if pos == 'noun':\n",
    "            pos = 'n';\n",
    "        if pos == 'adjective' or pos == 'adj':\n",
    "            pos = 'a';\n",
    "        if pos == 'verb':\n",
    "            pos = 'v';\n",
    "        if pos == 'adverb' or pos == 'adv':\n",
    "            pos = 'r';\n",
    "        mkey = sid + '_' + pos;\n",
    "        model[ mkey] = val;\n",
    "    return model;\n",
    "\n",
    "# To remove almost zero vectors\n",
    "def filter_zero_vectors( model, eps):\n",
    "    to_remove = [];\n",
    "    for key in model:\n",
    "        val = model[ key];\n",
    "    if np.linalg.norm( val) < eps:\n",
    "        to_remove.append( key);\n",
    "    for elem in to_remove:\n",
    "        del model[ elem];\n",
    "    return model;\n",
    "\n",
    "# create dictionary of pos specific models\n",
    "def pos_dict( model):\n",
    "    ret_dict = dict();\n",
    "    pos_list = [ 'a', 'n', 'r', 'v'];\n",
    "    for pos in pos_list:\n",
    "        ret_dict[ pos] = dict();\n",
    "    for key in model:\n",
    "        if 'a' in key:\n",
    "            ret_dict[ 'a'][ key] = model[ key];\n",
    "        if 'n' in key:\n",
    "            ret_dict[ 'n'][ key] = model[ key];\n",
    "        if 'r' in key:\n",
    "            ret_dict[ 'r'][ key] = model[ key];\n",
    "        if 'v' in key:\n",
    "            ret_dict[ 'v'][ key] = model[ key];\n",
    "    \n",
    "\n",
    "# Read a specific link file\n",
    "def read_link_file( lfname):\n",
    "    f = open( lfname, 'r');\n",
    "    link_data = [];\n",
    "    for line in f:\n",
    "        tokens = line.strip().split('\\t');\n",
    "        link_data.append( ( tokens[ 0], tokens[ 2]));\n",
    "    f.close();\n",
    "    return link_data;\n",
    "\n",
    "# Filter link list data by availability of synset vectors\n",
    "def filter_link_list( link_list, src_model, tgt_model, pos):\n",
    "    ret_list = [];\n",
    "    for tup in link_list:\n",
    "        src_id = tup[ 0];\n",
    "        tgt_id = tup[ 1];\n",
    "        src_str = str( src_id) + '_' + pos;\n",
    "        tgt_str = str( tgt_id) + '_' + pos;\n",
    "        if src_str in src_model and tgt_str in tgt_model:\n",
    "            ret_list.append( tup);\n",
    "    return ret_list;\n",
    "\n",
    "# training models for all dimensions of the tgt language synset vector\n",
    "def train_s2t( train_list, inp_m, out_m, pos = 'n', bias_p = False):\n",
    "    ivlist = [];\n",
    "    ovlist = [];\n",
    "    for tup in train_list:\n",
    "        k1, k2 = tup;\n",
    "        ivlist.append( inp_m[ k1]);\n",
    "        ovlist.append( out_m[ k2]);\n",
    "    i_data = np.asarray( ivlist, dtype = 'f4');\n",
    "    o_data = np.asarray( ovlist, dtype = 'f4');\n",
    "    dim = len( o_data[ 0]);\n",
    "    #print( dim);\n",
    "    dmodel_list = [];\n",
    "    print( 'Training', flush = True);\n",
    "    for i in range( dim):\n",
    "        #print( 'Dim = ', i, flush = True);\n",
    "        X = i_data;\n",
    "        Y = o_data[ :, i];\n",
    "        cur_model = LinearRegression( fit_intercept = bias_p);\n",
    "        cur_model.fit( X, Y);\n",
    "        dmodel_list.append( cur_model);\n",
    "    return dmodel_list;\n",
    "\n",
    "# applying models to test data\n",
    "def apply_model( model_list, test_list, inp_m, out_m, pos = 'n'):\n",
    "    ivlist = [];\n",
    "    ovlist = [];\n",
    "    for tup in test_list:\n",
    "        k1, k2 = tup;\n",
    "        ivlist.append( inp_m[ k1]);\n",
    "        #ovlist.append( out_m[ k2]);\n",
    "    i_data = np.array( ivlist, dtype = 'f4');\n",
    "    dim = len( ovlist[ 0]);\n",
    "    ypred = [];\n",
    "    print( 'Translating', flush = True);\n",
    "    for i in range( dim):\n",
    "        #print( 'Dim = ', i, flush = True);\n",
    "        X = i_data;\n",
    "        cur_model = model_list[ i];\n",
    "        Yp = cur_model.predict( X);\n",
    "        ypred.append( Yp);\n",
    "    pred_data = ypred[ 0];\n",
    "    for i in range( 1, dim):\n",
    "        pred_data = np.column_stack( ( pred_data, ypred[ i]));\n",
    "    #print( np.shape( pred_data));\n",
    "    return pred_data;\n",
    "\n",
    "# computing accuracy of a fold\n",
    "def get_acc( test_list, inp_m, out_m, pred_data, pos = 'n'):\n",
    "    print( 'Sim Scoring', flush = True);\n",
    "    ivlist = [];\n",
    "    ovlist = [];\n",
    "    ptr = 0;\n",
    "    k2id = dict();\n",
    "    id2k = dict();\n",
    "    for key in out_m:\n",
    "        ovlist.append( out_m[ key]);\n",
    "        k2id[ key] = ptr;\n",
    "        id2k[ ptr] = key;\n",
    "        ptr += 1;\n",
    "    o_data = np.asarray( ovlist, dtype = 'f4');\n",
    "    no_data = ( o_data.T / np.linalg.norm( o_data, axis = 1)).T;\n",
    "    npred_data = ( pred_data.T / np.linalg.norm( pred_data, axis = 1)).T;\n",
    "    sim_mat = npred_data.dot( no_data.T);\n",
    "    r, c = np.shape( sim_mat);\n",
    "    #trim_sim_mat = np.sort( sim_mat)[ :, ::-1];\n",
    "    trim_ind_mat = np.argsort( sim_mat)[ :, ::-1];\n",
    "    indx = [];\n",
    "    #posl = [];\n",
    "    print( 'Ranking', flush = True);\n",
    "    for i in range( r):\n",
    "        true = test_list[ i][ 1];\n",
    "        pos = test_list[ i][ 2];\n",
    "        tlist = trim_ind_mat[ i].tolist();\n",
    "        tind = tlist.index( k2id[ true]);\n",
    "        indx.append( tind);\n",
    "        #posl.append( pos);\n",
    "    acc_01 = sum( [ elem < 1 for elem in indx]);\n",
    "    acc_03 = sum( [ elem < 3 for elem in indx]);\n",
    "    acc_05 = sum( [ elem < 5 for elem in indx]);\n",
    "    acc_08 = sum( [ elem < 8 for elem in indx]);\n",
    "    acc_10 = sum( [ elem < 10 for elem in indx]);\n",
    "    acc_20 = sum( [ elem < 20 for elem in indx]);\n",
    "    acc_50 = sum( [ elem < 50 for elem in indx]);\n",
    "    acc_100 = sum( [ elem < 100 for elem in indx]);\n",
    "    #avg_cnt = sum( [ elem == true for elem in indx])\n",
    "    print( acc_01 / len( indx));\n",
    "    print( acc_03 / len( indx));\n",
    "    print( acc_05 / len( indx));\n",
    "    print( acc_08 / len( indx));\n",
    "    print( acc_10 / len( indx));\n",
    "    print( acc_20 / len( indx));\n",
    "    print( acc_50 / len( indx));\n",
    "    print( acc_100 / len( indx));\n",
    "    print( min( indx), max( indx), ptr);\n",
    "\n",
    "# cross validation\n",
    "def cross_validation( inp_m, out_m, link_list, pos = 'n', bias_p = False):\n",
    "    fold_beg = [ 0] * 10;\n",
    "    fold_end = [ 0] * 10;\n",
    "    for i in range( 1, 10):\n",
    "        fold_end[ i - 1] = (len( link_list) // 10) * i;\n",
    "        fold_beg[ i] = (len( link_list) // 10) * i;\n",
    "    fold_end[ 9] = len( link_list);\n",
    "    for fold_ptr in range( 10):\n",
    "        print( 'Running fold ', fold_ptr, flush = True);\n",
    "        train_list = [];\n",
    "        test_list = [];\n",
    "        for i in range( 10):\n",
    "            if i != fold_ptr:\n",
    "                train_list.extend( link_list[ fold_beg[ i] : fold_end[ i]]);\n",
    "            else:\n",
    "                test_list.extend( link_list[ fold_beg[ i] : fold_end[ i]]);\n",
    "        dmodel_list = train_s2t( train_list, inp_m, out_m, pos, bias_p);\n",
    "        pred_data = apply_model( dmodel_list, test_list, inp_m, out_m, pos);\n",
    "        get_acc( test_list, inp_m, out_m, pred_data, pos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
